{
  "os":  "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
  "python":  "CPython 3.10.19",
  "startedAt":  "2026-01-12T03:56:05.881999Z",
  "args":  [
    "--local_rank=0",
    "--deepspeed",
    "configs/ds_config_zero2_no_offload.json",
    "--full_finetune",
    "False",
    "--model_name_or_path",
    "meta-llama/Llama-2-7b-hf",
    "--seed",
    "42",
    "--data_seed",
    "42",
    "--base_dtype",
    "int4",
    "--adapter_dtype",
    "fp32",
    "--init_weights",
    "lava",
    "--lora_rank",
    "128",
    "--lora_alpha",
    "16",
    "--lora_dropout",
    "0",
    "--target_modules",
    "q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj",
    "--data_path",
    "fxmeng/pissa-dataset",
    "--sub_task",
    "conversation",
    "--dataset_split",
    "train",
    "--dataset_field",
    "instruction",
    "output",
    "--output_dir",
    "output/conversation-LAVA-mistral-r128-B_int4-A_fp32-vib2.0-seed42",
    "--num_train_epochs",
    "1",
    "--model_max_length",
    "256",
    "--per_device_train_batch_size",
    "4",
    "--gradient_checkpointing",
    "True",
    "--gradient_accumulation_steps",
    "32",
    "--learning_rate",
    "1e-4",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "10",
    "--save_strategy",
    "steps",
    "--save_steps",
    "1000",
    "--save_total_limit",
    "1",
    "--report_to",
    "wandb",
    "--optim",
    "adamw_torch",
    "--merge",
    "False",
    "--lambda_vib",
    "2.0",
    "--lambda_stab",
    "0.1",
    "--lambda_latent_stability",
    "1.0"
  ],
  "program":  "/home/dongwoo38/PiSSA/train.py",
  "codePath":  "train.py",
  "codePathLocal":  "train.py",
  "git":  {
    "remote":  "https://github.com/merrybabyxmas/lava2.git",
    "commit":  "4b4102dd787cd43bc1ec79fa604da20e8bec6b4f"
  },
  "email":  "yein0330@sogang.ac.kr",
  "root":  "/home/dongwoo38/PiSSA",
  "host":  "user-WRX80-Creator",
  "executable":  "/home/dongwoo38/miniconda3/envs/pissa/bin/python3.10",
  "cpu_count":  24,
  "cpu_count_logical":  48,
  "gpu":  "NVIDIA GeForce RTX 4090",
  "gpu_count":  4,
  "disk":  {
    "/":  {
      "total":  "1966736678912",
      "used":  "1427090792448"
    }
  },
  "memory":  {
    "total":  "134894309376"
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA GeForce RTX 4090",
      "memoryTotal":  "25757220864",
      "cudaCores":  16384,
      "architecture":  "Ada",
      "uuid":  "GPU-1a133bd2-ae1e-86f3-56bf-38518f125ad4"
    },
    {
      "name":  "NVIDIA GeForce RTX 4090",
      "memoryTotal":  "25757220864",
      "cudaCores":  16384,
      "architecture":  "Ada",
      "uuid":  "GPU-6068f209-96d6-139d-80fb-7db74591f8b4"
    },
    {
      "name":  "NVIDIA GeForce RTX 4090",
      "memoryTotal":  "25757220864",
      "cudaCores":  16384,
      "architecture":  "Ada",
      "uuid":  "GPU-4f8fb1fe-e7c5-aad3-6f94-a16bee1178a0"
    },
    {
      "name":  "NVIDIA GeForce RTX 4090",
      "memoryTotal":  "25757220864",
      "cudaCores":  16384,
      "architecture":  "Ada",
      "uuid":  "GPU-760bf631-f8cc-ccc4-3350-5f6d4379dbe5"
    }
  ],
  "cudaVersion":  "13.0",
  "writerId":  "k8fugxu3ld69uc2erldzfki8zhr7i2zz"
}