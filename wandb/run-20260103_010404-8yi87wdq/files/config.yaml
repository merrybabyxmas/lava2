_wandb:
    value:
        cli_version: 0.23.1
        e:
            dfr585ct8g0fa4gudwppk4uqaldc1aaj:
                args:
                    - --base_model
                    - meta-llama/Llama-2-7b-hf
                    - --adapter_path
                    - /home/dongwoo38/PiSSA/output/conversation-LAVA-Llama-2-7b-r128_seed42_bs64_bf16/checkpoint-26811/adapter_model
                    - --model_id
                    - Qlora-r128-4bit
                    - --num_questions
                    - "80"
                    - --wandb_project
                    - MT-Bench-Eval
                    - --wandb_name
                    - lava-r128-4bit-eval
                codePath: mtbench_for_peft.py
                codePathLocal: mtbench_for_peft.py
                cpu_count: 24
                cpu_count_logical: 48
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "1966736678912"
                        used: "1330658177024"
                email: yein0330@sogang.ac.kr
                executable: /home/dongwoo38/miniconda3/envs/pissa/bin/python
                git:
                    commit: a6e4c9c1d8bc1b73c0fd2f524be8e00e26043395
                    remote: https://github.com/GraphPKU/PiSSA.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 4
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-1a133bd2-ae1e-86f3-56bf-38518f125ad4
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-6068f209-96d6-139d-80fb-7db74591f8b4
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-4f8fb1fe-e7c5-aad3-6f94-a16bee1178a0
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-760bf631-f8cc-ccc4-3350-5f6d4379dbe5
                host: user-WRX80-Creator
                memory:
                    total: "134894039040"
                os: Linux-6.14.0-36-generic-x86_64-with-glibc2.39
                program: /home/dongwoo38/PiSSA/mtbench_for_peft.py
                python: CPython 3.10.19
                root: /home/dongwoo38/PiSSA
                startedAt: "2026-01-02T16:04:04.732035Z"
                writerId: dfr585ct8g0fa4gudwppk4uqaldc1aaj
        m: []
        python_version: 3.10.19
        t:
            "1":
                - 1
                - 11
                - 49
                - 71
                - 98
                - 105
            "2":
                - 1
                - 11
                - 49
                - 71
                - 95
                - 98
                - 105
            "3":
                - 2
                - 13
                - 16
                - 61
            "4": 3.10.19
            "5": 0.23.1
            "6": 4.45.1
            "12": 0.23.1
            "13": linux-x86_64
adapter_path:
    value: /home/dongwoo38/PiSSA/output/conversation-LAVA-Llama-2-7b-r128_seed42_bs64_bf16/checkpoint-26811/adapter_model
base_model:
    value: meta-llama/Llama-2-7b-hf
model_id:
    value: Qlora-r128-4bit
num_questions:
    value: 80
wandb_name:
    value: lava-r128-4bit-eval
wandb_project:
    value: MT-Bench-Eval
