{
  "os":  "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
  "python":  "CPython 3.10.19",
  "startedAt":  "2026-01-11T17:16:27.806646Z",
  "args":  [
    "--local_rank=0",
    "--deepspeed",
    "configs/ds_config_zero2_no_offload.json",
    "--full_finetune",
    "False",
    "--model_name_or_path",
    "mistralai/Mistral-7B-v0.1",
    "--seed",
    "42",
    "--data_seed",
    "42",
    "--base_dtype",
    "int4",
    "--adapter_dtype",
    "fp32",
    "--init_weights",
    "lava",
    "--lora_rank",
    "128",
    "--lora_alpha",
    "16",
    "--lora_dropout",
    "0",
    "--target_modules",
    "q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj",
    "--data_path",
    "fxmeng/pissa-dataset",
    "--sub_task",
    "metamath:100000",
    "--dataset_split",
    "train",
    "--dataset_field",
    "instruction",
    "output",
    "--output_dir",
    "output/metamath-LAVA-mistral-r128-a16-B_int4-vib1.0-seed42",
    "--num_train_epochs",
    "1",
    "--model_max_length",
    "512",
    "--per_device_train_batch_size",
    "4",
    "--gradient_checkpointing",
    "True",
    "--gradient_accumulation_steps",
    "32",
    "--learning_rate",
    "1e-4",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "10",
    "--save_strategy",
    "steps",
    "--save_steps",
    "1000",
    "--save_total_limit",
    "1",
    "--report_to",
    "wandb",
    "--optim",
    "adamw_torch",
    "--merge",
    "False",
    "--lambda_vib",
    "1.0",
    "--lambda_stab",
    "0.1",
    "--lambda_latent_stability",
    "1.0"
  ],
  "program":  "/home/dongwoo38/PiSSA/train.py",
  "codePath":  "train.py",
  "codePathLocal":  "train.py",
  "git":  {
    "remote":  "https://github.com/merrybabyxmas/lava2.git",
    "commit":  "4b4102dd787cd43bc1ec79fa604da20e8bec6b4f"
  },
  "email":  "yein0330@sogang.ac.kr",
  "root":  "/home/dongwoo38/PiSSA",
  "host":  "user-WRX80-Creator",
  "executable":  "/home/dongwoo38/miniconda3/envs/pissa/bin/python3.10",
  "cpu_count":  24,
  "cpu_count_logical":  48,
  "disk":  {
    "/":  {
      "total":  "1966736678912",
      "used":  "1427135799296"
    }
  },
  "memory":  {
    "total":  "134894321664"
  },
  "writerId":  "x54l2l8kw08ojzv4ihgl951y0lpbdto3"
}